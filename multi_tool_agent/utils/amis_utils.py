# =============================================================================
# é˜¿ç¾æ—èªè©å…¸å·¥å…·å‡½æ•¸
# å¾é˜¿ç¾æ—èªè©å…¸ä¸­éš¨æ©Ÿé¸å–å–®å­—ä¸¦æä¾›è©³ç´°è§£é‡‹
# åŒ…å«å®šç¾©ã€åŒç¾©è©å’Œä¾‹å¥ç­‰è³‡è¨Š
# =============================================================================

import os
import json
import random
import logging

logger = logging.getLogger(__name__)


async def get_amis_word_of_the_day() -> dict:
    """
    å¾é˜¿ç¾æ—èªè©å…¸ä¸­éš¨æ©Ÿé¸å–ä¸€å€‹å–®å­—ä¸¦å›å‚³å…¶å®šç¾©ã€‚
    """
    try:
        # è®€å– amis.json æª”æ¡ˆ
        file_path = os.path.join(os.path.dirname(__file__), '..', '..', 'amis.json')
        with open(file_path, 'r', encoding='utf-8') as f:
            word_list = json.load(f)

        # éš¨æ©Ÿé¸å–ä¸€å€‹å–®å­—
        word_data = random.choice(word_list)

        amis_word = word_data.get("title", "N/A")

        # å¾ heteronyms ä¸­ç²å–æ‰€æœ‰å®šç¾©ã€åŒç¾©è©å’Œä¾‹å¥
        definitions_list = []
        all_synonyms = []
        all_examples = []

        heteronyms = word_data.get("heteronyms", [])
        for heteronym in heteronyms:
            definitions = heteronym.get("definitions", [])
            for def_item in definitions:
                # ç²å–å®šç¾©ï¼ˆå¯èƒ½åŒ…å«è‹±æ–‡å’Œä¸­æ–‡ï¼‰
                def_text = def_item.get("def", "")

                # æå–ä¸­æ–‡éƒ¨åˆ†
                chinese_def = _extract_chinese_definition(def_text)
                if chinese_def:
                    definitions_list.append(chinese_def)

                # æ”¶é›†åŒç¾©è©
                synonyms = def_item.get("synonyms", [])
                all_synonyms.extend(synonyms)

                # æ”¶é›†ä¾‹å¥
                examples = def_item.get("example", [])
                all_examples.extend(examples)

        # æ ¼å¼åŒ–å ±å‘Š
        if definitions_list:
            if len(definitions_list) == 1:
                report = f"ğŸ“– é˜¿ç¾æ—èªæ¯æ—¥ä¸€å­—ï¼š{amis_word}\n\nğŸ“œ ä¸­æ–‡æ„æ€ï¼š{definitions_list[0]}"
            else:
                # å¤šå€‹å®šç¾©ï¼Œç”¨ç·¨è™Ÿé¡¯ç¤º
                defs_text = "\n".join([f"{i+1}. {def_text}" for i, def_text in enumerate(definitions_list)])
                report = f"ğŸ“– é˜¿ç¾æ—èªæ¯æ—¥ä¸€å­—ï¼š{amis_word}\n\nğŸ“œ ä¸­æ–‡æ„æ€ï¼š\n{defs_text}"
        else:
            report = f"ğŸ“– é˜¿ç¾æ—èªæ¯æ—¥ä¸€å­—ï¼š{amis_word}\n\nğŸ“œ ä¸­æ–‡æ„æ€ï¼šç„¡å®šç¾©è³‡æ–™"

        # è™•ç†åŒç¾©è©ï¼ˆå»é‡ä¸¦æ¸…ç†æ ¼å¼ï¼‰
        if all_synonyms:
            cleaned_synonyms = _clean_synonyms(all_synonyms, word_list)
            if cleaned_synonyms:
                synonym_text = "ã€".join(cleaned_synonyms)
                report += f"\n\nğŸ”— åŒç¾©è©ï¼š{synonym_text}"

        # è™•ç†ä¾‹å¥
        if all_examples:
            cleaned_examples = _clean_examples(all_examples)
            if cleaned_examples:
                if len(cleaned_examples) == 1:
                    report += f"\n\nğŸ’¬ ä¾‹å¥ï¼š{cleaned_examples[0]}"
                else:
                    examples_text = "\n".join([f"{i+1}. {example}" for i, example in enumerate(cleaned_examples)])
                    report += f"\n\nğŸ’¬ ä¾‹å¥ï¼š\n{examples_text}"

        return {
            "status": "success",
            "report": report
        }
    except FileNotFoundError:
        logger.error("amis.json æª”æ¡ˆä¸å­˜åœ¨")
        return {
            "status": "error",
            "error_message": "æ‰¾ä¸åˆ°é˜¿ç¾æ—èªè©å…¸æª”æ¡ˆã€‚"
        }
    except Exception as e:
        logger.error(f"è™•ç†é˜¿ç¾æ—èªæ¯æ—¥ä¸€å­—æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return {
            "status": "error",
            "error_message": f"è™•ç†æ¯æ—¥ä¸€å­—æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}"
        }


def _extract_chinese_definition(def_text):
    """æå–å®šç¾©ä¸­çš„ä¸­æ–‡éƒ¨åˆ†"""
    if not def_text:
        return ""

    # æ–¹æ³•1: å°‹æ‰¾ * åˆ†éš”ç¬¦
    if "*" in def_text:
        parts = def_text.split("*")
        return parts[-1].strip() if len(parts) > 1 else def_text

    # æ–¹æ³•2: å°‹æ‰¾ç¬¬ä¸€å€‹ä¸­æ–‡å­—ç¬¦é–‹å§‹çš„éƒ¨åˆ†
    words = def_text.split()
    chinese_start = -1
    for i, word in enumerate(words):
        if any('\u4e00' <= char <= '\u9fff' for char in word):
            chinese_start = i
            break

    if chinese_start != -1:
        return " ".join(words[chinese_start:])

    # æ–¹æ³•3: å¦‚æœéƒ½æ²’æœ‰ï¼Œè¿”å›åŸæ–‡
    return def_text


def _clean_synonyms(synonyms, word_list):
    """æ¸…ç†åŒç¾©è©ä¸¦é©—è­‰æ˜¯å¦å­˜åœ¨"""
    cleaned = []
    for synonym in synonyms:
        if synonym:
            # ç§»é™¤ç‰¹æ®Šç¬¦è™Ÿï¼ˆå¦‚ `karahay~ -> karahayï¼‰
            clean_word = synonym.strip('`~')

            # æª¢æŸ¥æ˜¯å¦åœ¨è©å…¸ä¸­å­˜åœ¨
            if _word_exists_in_dict(clean_word, word_list):
                # é¡¯ç¤ºåŸå§‹æ ¼å¼
                cleaned.append(synonym)
            else:
                # å¦‚æœæ¸…ç†å¾Œçš„è©å­˜åœ¨ï¼Œé¡¯ç¤ºæ¸…ç†å¾Œçš„
                if _word_exists_in_dict(synonym, word_list):
                    cleaned.append(synonym)
                else:
                    # å³ä½¿ä¸å­˜åœ¨ä¹Ÿä¿ç•™ï¼Œå¯èƒ½æ˜¯å¼•ç”¨æ ¼å¼
                    cleaned.append(synonym)

    # å»é‡
    return list(dict.fromkeys(cleaned))


def _word_exists_in_dict(word, word_list):
    """æª¢æŸ¥å–®å­—æ˜¯å¦å­˜åœ¨æ–¼è©å…¸ä¸­"""
    for item in word_list:
        if item.get("title", "").lower() == word.lower():
            return True
    return False


def _clean_examples(examples):
    """æ¸…ç†å’Œæ ¼å¼åŒ–ä¾‹å¥"""
    cleaned = []
    for example in examples:
        if example and example.strip():
            # ç§»é™¤é–‹é ­çš„ç©ºæ ¼
            clean_example = example.strip()

            # åˆ†æä¾‹å¥çµæ§‹ï¼šé€šå¸¸æ˜¯ é˜¿ç¾èª + è‹±æ–‡ + ä¸­æ–‡
            # ä¾‹å¦‚ï¼š`pasamo~ `to~ `sowal~ give the gist of the matter in words èªªè¦é»ï¼Œå³èˆˆç•¥èªªäº‹æƒ…çš„è¦æ—¨
            formatted_example = _format_example(clean_example)

            cleaned.append(formatted_example)

    # å»é‡ä½†ä¿æŒé †åº
    return list(dict.fromkeys(cleaned))


def _format_example(example):
    """æ ¼å¼åŒ–å–®å€‹ä¾‹å¥ï¼Œæ·»åŠ é©ç•¶çš„æ›è¡Œ"""
    # æ‰¾å°‹è‹±æ–‡å’Œä¸­æ–‡çš„åˆ†ç•Œé»
    words = example.split()

    # å°‹æ‰¾ç¬¬ä¸€å€‹ä¸­æ–‡å­—ç¬¦çš„ä½ç½®
    chinese_start = -1
    for i, word in enumerate(words):
        if any('\u4e00' <= char <= '\u9fff' for char in word):
            chinese_start = i
            break

    if chinese_start > 0:
        # åˆ†é›¢é˜¿ç¾èª+è‹±æ–‡ å’Œ ä¸­æ–‡éƒ¨åˆ†
        amis_english = " ".join(words[:chinese_start])
        chinese = " ".join(words[chinese_start:])

        # æ ¼å¼åŒ–ï¼šé˜¿ç¾èª+è‹±æ–‡ æ›è¡Œ ä¸­æ–‡
        return f"{amis_english}\nâ†’ {chinese}"
    else:
        # å¦‚æœæ²’æœ‰ä¸­æ–‡æˆ–æ ¼å¼ä¸æ¨™æº–ï¼Œç›´æ¥è¿”å›
        return example